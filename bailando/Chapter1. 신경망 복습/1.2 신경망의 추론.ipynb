{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 신경망의 추론\n",
    "신경망을 복습해보자. 신경망에서 수행하는 작업은'학습'과 '추론' 두 단계로 나눌 수 있다.  \n",
    "이번 절에서 '추론'에 대해 살펴본다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 신경망 추론 전체 그림\n",
    "신경망은 단순한 '함수'이다. 무엇을 입력하면 출력으로 변환한다.\n",
    "2차원 데이터를 입력해 3차원 데이터를 출력하는 함수를 예로 들면 입력층에 뉴런 2개를, 출력층에 3개를 각 준비한다. 그리고 은닉층(중간층)에도 적당한 수의 뉴런을 배치한다.\n",
    "\n",
    "그럼 이런 신경망 모습을 그릴 수 있다.  \n",
    "\n",
    "       ㅇ ---> ㅇ ---> ㅇ  \n",
    "       ㅇ ---> ㅇ ---> ㅇ  \n",
    "              ㅇ ---> ㅇ    \n",
    "              ㅇ\n",
    "       input  hidden output\n",
    "(그림상 이렇지만 각 노드들은 모두 서로 연결되어 있음)  \n",
    "각 화살표에는 가중치가 존재하며, 그  가중치와 뉴런의 값을 각가 곱해서 그 합이 다음 뉴런의 입력으로 쓰인다. (정확하게는 그 값에 활성화 함수를 적용해서) 이때 각 층에서는 이전 뉴런값에 영향받지 않는 'bias' 편향 값도 더해진다.  이렇게 모든 뉴런이 연결되어 있는 신경망을 완전연결계층이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N개의 데이터를 처리하는 완전연결계층 미니배치 구현\n",
    "import numpy as np\n",
    "\n",
    "W1 = np.random.randn(2,4)   # 가중치\n",
    "b1 = np.random.randn(4)     # 편향\n",
    "x = np.random.randn(10,2)   # 입력\n",
    "\n",
    "h = np.matmul(x,W1) + b1    # 행렬곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전연결계층에 의한 변환은 '선형'변환이다. 여기에 '비선형'효과를 더하는 것이 활성화 함수이다. 여기서는 시그모이드 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종정리\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# input\n",
    "x = np.random.randn(10, 2)\n",
    "\n",
    "# 1st layer\n",
    "W1 = np.random.randn(2, 4)\n",
    "b1 = np.random.randn(4)\n",
    "\n",
    "# 2nd layer\n",
    "W2 = np.random.randn(4, 3)\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "# forward\n",
    "h = np.matmul(x, W1) + b1\n",
    "a = sigmoid(h)\n",
    "s = np.matmul(a, W2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. 계층으로 클래스화 및 순전파 구현\n",
    "신경망에서 하는 처리를 계층으로 구현해본다. 완전연결계층에 의한 변환을 Affine 계층으로, 시그모이드 함수에 의한 변환을 Sigmoid 계층으로 구현한다.\n",
    "신경망을 구현할 때 다음의 구현 규칙을 따른다.\n",
    "- 모든 계층은 forward()와 backward() 메서드를 갖는다.\n",
    "- 모든 계층은 인스턴스 변수인 params와 grads를 갖는다.\n",
    "\n",
    "이번절에서는 순전파를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 클래스를 이용해 두개의 레이어를 가진 신경망을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        # 가중치와 편향 초기화\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "\n",
    "        # 모든 가중치를 리스트에 모은다.\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.00468848, -0.44554985,  0.94609825, -0.85659414],\n",
       "        [ 0.27203115, -2.52312974, -0.61654743, -0.68147235]]),\n",
       " array([0.61096075, 1.07612968, 0.57846649, 1.40806188]),\n",
       " array([[ 0.30219731, -0.11782003, -1.34183137],\n",
       "        [-0.51175314,  1.08172581, -0.68370835],\n",
       "        [ 1.02615617, -1.11049703, -0.78652221],\n",
       "        [-0.02441465,  0.85362359,  0.8113523 ]]),\n",
       " array([ 0.66136721, -1.02364077,  0.5404336 ])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('estud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "391b1e7ce2e81530d6fa13507e2cf4fd1c09c0aaf5e54d082942efacf0dd49e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
